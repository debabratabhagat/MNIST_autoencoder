{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.nn import Module, ModuleList, Conv2d, ConvTranspose2d\n",
    "from torch.nn import ReLU, BCELoss, Sigmoid\n",
    "from torch.utils.data import Subset\n",
    "from torch.optim import Adam\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "batch_size = 64\n",
    "epoch = 50\n",
    "lr = 0.01\n",
    "num_workers = 4\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pin_memory = True if device == \"cuda\" else False\n",
    "\n",
    "base_output = \"output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = T.Compose(\n",
    "    [T.ToTensor()]\n",
    "    )\n",
    "\n",
    "train = Subset(datasets.MNIST(root=\"./data\", train = True, download = True, transform = transforms), range(2000))\n",
    "test = Subset(datasets.MNIST(root=\"./data\", train = False, download = True, transform = transforms), range(2000))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_dataloader = DataLoader(train, shuffle = True, batch_size=batch_size, num_workers = num_workers if torch.cuda.is_available() else 0, pin_memory = pin_memory)\n",
    "    test_dataloader = DataLoader(test, shuffle = True, batch_size=batch_size, num_workers = num_workers if torch.cuda.is_available() else 0, pin_memory = pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MODEL(Module):\n",
    "    def __init__(self, channels = [1, 16, 32, 64], bottleneck_dim = 484):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.bottleneck_dim = bottleneck_dim\n",
    "\n",
    "        self.encoder = ModuleList([\n",
    "            Conv2d(channels[i], channels[i+1], 3) for i in range (len(channels)-1)\n",
    "        ])\n",
    "\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Linear(channels[-1] * 22 * 22, bottleneck_dim * 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(bottleneck_dim * 3, bottleneck_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(bottleneck_dim * 2, bottleneck_dim * 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(\n",
    "                bottleneck_dim * 1, channels[-1] * 22 * 22\n",
    "            ),  # Output correct shape\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.unflatten = nn.Unflatten(1, (channels[-1], 22, 22))\n",
    "        \n",
    "        \n",
    "        self.decoder = ModuleList([\n",
    "            ConvTranspose2d(channels[len(channels)-1-i], channels[len(channels)-2-i], 3) for i in range (len(channels)-1)\n",
    "        ])\n",
    "        self.relu  =ReLU()\n",
    "        self.sigmoid = Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoderList = []\n",
    "        decoderList = []\n",
    "\n",
    "        for i in range(len(self.channels) -1):\n",
    "            x = self.encoder[i](x)\n",
    "            encoderList.append(x)\n",
    "            x = self.relu(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.bottleneck(x)\n",
    "        x = self.unflatten(x)\n",
    "        \n",
    "        for i in range(len(self.channels) -1):\n",
    "            x = self.decoder[i](x)\n",
    "            if i < len(self.decoder) - 1:  # Apply ReLU to all but last layer\n",
    "                x = self.relu(x)\n",
    "            decoderList.append(x) \n",
    "        \n",
    "        x = self.sigmoid(x)\n",
    "        return (x, encoderList, decoderList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.randn(1,1, 28, 28)\n",
    "model = MODEL()\n",
    "output = model.forward(sample)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderlist= output[1]\n",
    "decoderlist= output[2]\n",
    "\n",
    "for i in range(len(encoderlist)):\n",
    "    print(f\"Encoder List : {encoderlist[i].shape}\")\n",
    "print()\n",
    "for i in range(len(encoderlist)):\n",
    "    print(f\"Decoder List : {decoderlist[i].shape}\") \n",
    "\n",
    "print(\"\\n\", torch.flatten(encoderlist[-1], start_dim = 1).shape) \n",
    "# dim = 1 preserves the batches or in this case filters\n",
    "# [64, 22, 22] becomes [64, 484]\n",
    "\n",
    "# Before training\n",
    "plt.imshow(decoderlist[-1].detach().numpy().squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MODEL().to(device=device)\n",
    "lossFunc = BCELoss()\n",
    "opt = Adam(model.parameters(), lr = lr)\n",
    "\n",
    "trainsteps = len(train) // batch_size\n",
    "teststeps = len(test) // batch_size\n",
    "\n",
    "h = {\"train_loss\": [], \"test_loss\": []}\n",
    "\n",
    "for e in tqdm(range(epoch)):\n",
    "    model.train()\n",
    "\n",
    "    totaltrainloss = 0\n",
    "    totaltestloss = 0\n",
    "\n",
    "    for x, _ in train_dataloader:\n",
    "        x = x.to(device)\n",
    "\n",
    "        pred = model(x)[0]\n",
    "        loss = lossFunc(pred, x)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        totaltrainloss += loss\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for x, _ in test_dataloader:\n",
    "            x = x.to(device)\n",
    "\n",
    "            pred = model(x)[0]\n",
    "            loss = lossFunc(pred, x)\n",
    "\n",
    "            totaltestloss += loss\n",
    "\n",
    "    avgtrainloss = totaltrainloss / trainsteps\n",
    "    avgtestloss = totaltestloss / teststeps\n",
    "\n",
    "    h[\"train_loss\"].append(avgtrainloss.detach().numpy())\n",
    "    h[\"test_loss\"].append(avgtestloss.detach().numpy())\n",
    "\n",
    "    print(f\"[INFO] EPOCH : {e+1}/{epoch}\")\n",
    "    print(f\"[INFO] TRAIN LOSS : {avgtrainloss} --- TEST LOSS : {avgtestloss}\")\n",
    "\n",
    "    if e+1 % 10 == 0:\n",
    "        print(\"INFO MODEL SAVED\")\n",
    "        torch.save(model, os.path.join(base_output, f\"model_{e}.pth\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = torch.load(os.path.join(base_output, f\"model_{40}.pth\"), weights_only=False)\n",
    "trained_model.eval()\n",
    "\n",
    "plt.imshow(test[0][0].squeeze())\n",
    "plt.show()\n",
    "plt.imshow(trained_model(test[0][0])[0].cpu().detach().numpy().squeeze())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
